{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Project Title**\n",
        "\n",
        "ResQRelief: Integrated Disaster Impact Prediction and Response Management System\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "IFqX0IaA4aFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**\n",
        "\n",
        "Disasters such as floods, earthquakes, and cyclones cause large-scale damage to lives, infrastructure, and the economy. The major challenge during these events is not only predicting when and how severe they will be, but also managing the response effectively to reduce losses and support faster recovery.  \n",
        "\n",
        "Most existing projects focus on a single type of disaster, which limits their usefulness.  \n",
        "There is a need for an integrated system that can analyze different disaster datasets, predict potential impacts, and provide insights to support timely, data-driven decision-making for response and resource management.\n"
      ],
      "metadata": {
        "id": "nL9QJ2fQ6ZHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "ResQRelief uses disaster-related datasets (starting with flood impact data) to build predictive models that estimate the severity and consequences of disasters.  \n",
        "By analyzing historical patterns and contextual factors, the system can guide emergency preparedness, resource allocation, and response planning.  \n",
        "While the initial focus is on floods, the framework is designed to extend to other disasters such as earthquakes and cyclones.\n"
      ],
      "metadata": {
        "id": "RCvrfxAF9y9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#ML related imports\n",
        "\n",
        "#Model Selection\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "\n",
        "#Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "#Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error, r2_score\n",
        "\n",
        "#Save Models\n",
        "import joblib"
      ],
      "metadata": {
        "id": "FNPgQjBz_AQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Disaster(Flood) Datasets\n",
        "\n",
        "flood_data =pd.read_csv(\"flood.csv\")\n",
        "categories_data = pd.read_csv(\"disaster_categories.csv\")\n",
        "messages_data = pd.read_csv(\"disaster_messages.csv\")\n",
        "census_data = pd.read_csv(\"india-districts-census-2011.csv\")  # Make sure file name matches\n",
        "\n",
        "#display first few rows\n",
        "print(\"Flood Data:\")\n",
        "print(flood_data.head(),\"\\n\")\n",
        "\n",
        "print(\"Disaster Categories Data:\")\n",
        "print(categories_data.head(), \"\\n\")\n",
        "\n",
        "print(\"Disaster Messages Data:\")\n",
        "print(messages_data.head(), \"\\n\")\n",
        "\n",
        "print(\"Census/Population Data:\")\n",
        "print(census_data.head(), \"\\n\")"
      ],
      "metadata": {
        "id": "Yg11zw06DMnU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "mbDK_jdawb6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flood Data\n",
        "print(\"Flood Data Info:\")\n",
        "print(flood_data.info(), \"\\n\")\n",
        "print(\"Flood Data Description:\")\n",
        "print(flood_data.describe(), \"\\n\")\n",
        "print(\"Flood Data Missing Values:\")\n",
        "print(flood_data.isnull().sum(), \"\\n\")\n"
      ],
      "metadata": {
        "id": "nZnOme-qpLfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Disaster Categories Data\n",
        "print(\"Disaster Categories Data Info:\")\n",
        "print(categories_data.info(), \"\\n\")\n",
        "print(\"Disaster Categories Data Description:\")\n",
        "print(categories_data.describe(), \"\\n\")\n",
        "print(\"Disaster Categories Data Missing Values:\")\n",
        "print(categories_data.isnull().sum(), \"\\n\")\n"
      ],
      "metadata": {
        "id": "CmNIjEoMqxdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Disaster Messages Data ---\n",
        "print(\"Disaster Messages Data Info:\")\n",
        "print(messages_data.info(), \"\\n\")\n",
        "print(\"Disaster Messages Data Description:\")\n",
        "print(messages_data.describe(), \"\\n\")\n",
        "print(\"Disaster Messages Data Missing Values:\")\n",
        "print(messages_data.isnull().sum(), \"\\n\")"
      ],
      "metadata": {
        "id": "IXq0U57Nq5ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Census/Population Data ---\n",
        "print(\"Census Data Info:\")\n",
        "print(census_data.info(), \"\\n\")\n",
        "print(\"Census Data Description:\")\n",
        "print(census_data.describe(), \"\\n\")\n",
        "print(\"Census Data Missing Values:\")\n",
        "print(census_data.isnull().sum(), \"\\n\")"
      ],
      "metadata": {
        "id": "j3974_PSq-ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week 2: Exploratory Data Analysis (EDA), Data Transformation, and Feature Selection"
      ],
      "metadata": {
        "id": "aJ9VP9YGnwYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Messages Data Transformation"
      ],
      "metadata": {
        "id": "Ufd_IuB3d3Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Merge messages and categories datasets ---\n",
        "df_messages_combined = messages_data.merge(categories_data, on='id')\n",
        "print(\"Combined Messages & Categories Data Info:\")\n",
        "df_messages_combined.info()\n",
        "print(\"\\nCombined Messages & Categories Data Head:\")\n",
        "print(df_messages_combined.head())\n",
        "\n",
        "# --- Transform the 'categories' column into multiple binary columns ---\n",
        "# Split the categories column by semicolon\n",
        "categories_split = df_messages_combined['categories'].str.split(';', expand=True)\n",
        "\n",
        "# Create new column names from the first row of categories_split\n",
        "row = categories_split.iloc[0]\n",
        "category_colnames = row.apply(lambda x: x[:-2])\n",
        "categories_split.columns = category_colnames\n",
        "\n",
        "# Convert each new column to a binary integer (0 or 1)\n",
        "for column in categories_split:\n",
        "    categories_split[column] = categories_split[column].str[-1].astype(int)\n",
        "\n",
        "# Drop the original 'categories' column from the combined dataframe\n",
        "df_messages_combined.drop('categories', axis=1, inplace=True)\n",
        "\n",
        "# Concatenate the new binary columns to the combined dataframe\n",
        "df_messages_final = pd.concat([df_messages_combined, categories_split], axis=1)\n",
        "\n",
        "print(\"\\nFinal Transformed Messages Data Info:\")\n",
        "df_messages_final.info()\n",
        "print(\"\\nFinal Transformed Messages Data Head:\")\n",
        "print(df_messages_final.head())"
      ],
      "metadata": {
        "id": "scXMF4GccG5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EDA for Transformed Message Data ---\n",
        "# Count the number of messages for each category\n",
        "category_counts = df_messages_final.iloc[:, 4:].sum().sort_values(ascending=False)\n",
        "\n",
        "# Plot a bar chart to visualize the distribution of categories\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
        "plt.title('Distribution of Disaster Message Categories')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of Messages')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nPfsfxPxcZtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flood Data"
      ],
      "metadata": {
        "id": "-jq45q-bd6XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flood Data Shape and Columns\n",
        "print(\"Flood Data Shape:\", flood_data.shape)\n",
        "print(\"Flood Data Columns:\", flood_data.columns.tolist())\n",
        "\n",
        "# Univariate analysis for Flood Data\n",
        "\n",
        "target_col = \"FloodProbability\"  # Corrected target column\n",
        "\n",
        "# Countplot for target column\n",
        "sns.countplot(data=flood_data, x=target_col)\n",
        "plt.title(f\"Distribution of {target_col}\")\n",
        "plt.show()\n",
        "\n",
        "# Histograms for all numeric columns\n",
        "num_cols = flood_data.select_dtypes(include=np.number).columns\n",
        "\n",
        "fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, len(num_cols) * 3))\n",
        "\n",
        "for ax, col in zip(axes, num_cols):\n",
        "    sns.histplot(flood_data[col], kde=True, ax=ax)\n",
        "    ax.set_title(f\"Distribution of {col}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8CjrpqwDuqQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bivariate Analysis for Flood Data\n",
        "\n",
        "# Boxplot: Relationship of each numeric feature with FloodProbability\n",
        "fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, len(num_cols) * 3))\n",
        "\n",
        "for ax, col in zip(axes, num_cols):\n",
        "    if col != \"FloodProbability\":  # skip target column\n",
        "        sns.boxplot(data=flood_data, x=\"FloodProbability\", y=col, ax=ax)\n",
        "        ax.set_title(f\"{col} vs FloodProbability\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots: Example relationship between two important features\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=flood_data, x=\"MonsoonIntensity\", y=\"FloodProbability\")\n",
        "plt.title(\"Monsoon Intensity vs Flood Probability\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=flood_data, x=\"Urbanization\", y=\"FloodProbability\")\n",
        "plt.title(\"Urbanization vs Flood Probability\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bnPOFlhY6FpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap for Flood Data\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "corr = flood_data.corr()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Correlation Heatmap of Flood Data Features\")\n",
        "plt.show()\n",
        "\n",
        "# Pairplot for selected important features\n",
        "selected_cols = [\"MonsoonIntensity\", \"Urbanization\", \"Deforestation\", \"RiverManagement\", \"FloodProbability\"]\n",
        "\n",
        "sns.pairplot(flood_data[selected_cols], hue=\"FloodProbability\", diag_kind=\"kde\")\n",
        "plt.suptitle(\"Pairplot of Key Features Colored by Flood Probability\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZadWVZeP6yPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot for Flood Data\n",
        "sns.pairplot(flood_data, diag_kind=\"kde\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gfgz1Z8ZYqKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape & Columns\n",
        "print(\"Census Data Shape:\", census_data.shape)\n",
        "print(\"Census Data Columns:\", census_data.columns)\n",
        "\n",
        "# Histograms for numeric features\n",
        "num_cols_census = census_data.select_dtypes(include=np.number).columns\n",
        "fig, axes = plt.subplots(len(num_cols_census), 1, figsize=(8, len(num_cols_census)*3))\n",
        "for ax, col in zip(axes, num_cols_census):\n",
        "    sns.histplot(census_data[col], kde=True, ax=ax)\n",
        "    ax.set_title(f\"Distribution of {col}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(census_data.corr(), annot=False, cmap=\"YlGnBu\")\n",
        "plt.title(\"Correlation Heatmap - Census Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bVmdgnfbZwze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X = flood_data.drop(target_col, axis=1)\n",
        "y = flood_data[target_col]\n",
        "\n",
        "# Correlation with target\n",
        "corr_with_target = flood_data.corr()[target_col].sort_values(ascending=False)\n",
        "print(\"Correlation with Flood Probability:\\n\", corr_with_target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Scaling done. X_train_scaled shape:\", X_train_scaled.shape)\n"
      ],
      "metadata": {
        "id": "5EYX8dbBZw1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}